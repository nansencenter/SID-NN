{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import yaml\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import autokeras as ak #needed to have the definition of specific layers\n",
    "\n",
    "import numpy as np\n",
    "from dti_util import tile2im, get_score_importances, decode_dam, code_dam, unstack_training, clean_ax, rmse, corr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change default matplotlib\n",
    "mpl.rcParams['savefig.dpi']=150\n",
    "mpl.rcParams['savefig.bbox']='tight'\n",
    "mpl.rcParams['savefig.pad_inches']=0.05\n",
    "mpl.rcParams['axes.labelsize']=mpl.rcParams['axes.titlesize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the experiment\n",
    "#name = 'exp4'\n",
    "name = 'exp-smooth'\n",
    "suff ='_smooth'\n",
    "#suff = ''\n",
    "# Root of all directory used\n",
    "rootdir = '/mnt/sfe-ns9602k/Julien/data'\n",
    "\n",
    "#figdir\n",
    "figdir = '../overleaf/figs/'\n",
    "\n",
    "# Directory of the experiment outputs\n",
    "expdir = os.path.join(rootdir, name)\n",
    "\n",
    "# Load experiment parameters\n",
    "with open(os.path.join(expdir,'data_params.yml' )) as file:\n",
    "    exp_dict = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    \n",
    "# Print experiments parameters\n",
    "for key, value in exp_dict.items():\n",
    "    print(key, ' : ', value)\n",
    "    \n",
    "# Set the used parameters\n",
    "traindir = exp_dict['traindir']\n",
    "epsi = exp_dict['epsi']\n",
    "th_dam = exp_dict['th_dam']\n",
    "th_sit = exp_dict['th_sit']\n",
    "dsize = exp_dict['dsize']\n",
    "colnames = exp_dict['colnames']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization function\n",
    "norm = lambda x : code_dam(x,epsi=epsi, vmin=th_dam)\n",
    "\n",
    "# Denormalization function\n",
    "denorm = lambda x : decode_dam(x,epsi=epsi, vmin=th_dam)\n",
    "\n",
    "lims = {\n",
    "    'log_deformation_0': (-4, 1),\n",
    "    'log_deformation_1': (-4, 1),\n",
    "    'h':(th_sit,5),\n",
    "    'c':(0.9,1),\n",
    "    'damage_n' : [norm(1),norm(th_dam)],\n",
    "    'damage' : [th_dam, 1]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = np.load(os.path.join(traindir,'test.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = data_test['Xtest']\n",
    "ytest = denorm(data_test['ytest'])\n",
    "mask_test = data_test['mask_test']\n",
    "shape_original = data_test['shape_original']\n",
    "ntest, ny, nx = shape_original\n",
    "print (f'Size of the output image: {ny}x{nx}')\n",
    "X2, y2_test = unstack_training(Xtest, ytest, mask_test, ny=ny, nx=nx, strides=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test input feature\n",
    "for i, name in enumerate(colnames):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    im = ax.imshow(X2[0,...,i],vmin=lims[name][0],vmax=lims[name][1])\n",
    "    #fig.colorbar(im)\n",
    "    clean_ax([ax])\n",
    "    fig.savefig(os.path.join(figdir, f'imtest_{name}{suff}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test damage\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "dam = ax.imshow(y2_test[0],vmin=lims['damage'][0], vmax = lims['damage'][1],cmap='jet')\n",
    "clean_ax([ax])\n",
    "\n",
    "fig.savefig(os.path.join(figdir, f'imtest_damage.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Baseline and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Name of the model\n",
    "model_name = \"long\"\n",
    "#model_name = \"demo\"\n",
    "\n",
    "# Read model setting parameter from file\n",
    "from_file = True\n",
    "\n",
    "# pretrained model ( if False, launch a new training)\n",
    "pretrained = True\n",
    "\n",
    "# Directory to stores the model\n",
    "model_dir = os.path.join(expdir, model_name)\n",
    "\n",
    "# Create the model directory if necessary\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "# Dictionnary sotring all the mod setting parameters\n",
    "dmod = dict()\n",
    "\n",
    "if from_file:\n",
    "    # Read model parameters from yml file\n",
    "    with open(os.path.join(model_dir,'model_params.yml' )) as file:\n",
    "        dmod = yaml.load(file, Loader=yaml.FullLoader)        \n",
    "else:\n",
    "    # Create a yml file\n",
    "\n",
    "    # relative size of the validation dataset\n",
    "    dmod['test_size'] = 0.15\n",
    "\n",
    "    # Seed of the train/val random split\n",
    "    dmod['split_seed'] = 1\n",
    "\n",
    "    # log_dir for tensorboard\n",
    "    # log_dir is hardcoded because of NIRD toolkit, how to get the log name automatically?\n",
    "    dmod['log_dir'] = \"/mnt/sfe-ns9602k/.tools/deep-learn-1603280065-tensorboard/autokeras/{}-{}\".format(name, model_name)\n",
    "\n",
    "    # Shuffle score file name \n",
    "    dmod['fname_score_shuffle'] = 'shuffle_score'\n",
    "\n",
    "    # Saliency score file name \n",
    "    dmod['fname_score_saliency'] = 'saliency_score'\n",
    "\n",
    "    # Patience of the early stopping\n",
    "    dmod['patience'] = 15 #15 #5\n",
    "\n",
    "    # number of epochs\n",
    "    dmod['epochs'] = 300\n",
    "\n",
    "    # Number of trials of the model experiment\n",
    "    dmod['max_trials'] = 50 #50 #3\n",
    "\n",
    "    # Size of the training set (None for selecting all the training set)\n",
    "    dmod['ntrain']= None #None #10000\n",
    "\n",
    "    # Save the dictionary in yaml format\n",
    "    with open(os.path.join(model_dir,'model_params.yml'),'w') as file:\n",
    "        yaml.dump(dmod, file)\n",
    "\n",
    "        \n",
    "print ('--- MODEL CONFIGURATION ---')\n",
    "for key, value in dmod.items():\n",
    "    print(key, ' : ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(os.path.join(traindir,'train.npz'))\n",
    "X = data['Xtrain']\n",
    "y = data['ytrain']\n",
    "mask_train = data['mask_train']\n",
    "yd = denorm(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of training samples: {X.shape[0]}\")\n",
    "print(f'Size of input feature: {X.shape[1:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xval, ytrain, yval = train_test_split(X.astype(np.float32), y.astype(np.float32),\n",
    "                                                    test_size = dmod['test_size'],\n",
    "                                                    random_state = dmod['split_seed'])\n",
    "\n",
    "print(f\"Number of training samples: {Xtrain.shape[0]}\")\n",
    "print(f\"Number of validation samples: {Xval.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_ak(dd):\n",
    "    return np.clip(1.01 - 0.008/(10**dd)**0.3,0,1)\n",
    "\n",
    "xpoint = np.array([-3, -2.5, -2, -1.5, -1,  0])\n",
    "ypoint = np.array([.72, .25, -0.2, -.5, -0.7, -0.9])\n",
    "coef = np.polyfit(xpoint, ypoint, 2)\n",
    "print (f'Coefficients of the polynomial fit: {coef}')\n",
    "\n",
    "def reg_jb(x):\n",
    "    y = np.poly1d(coef)(x)\n",
    "    lim = -coef[1]/(2*coef[0])\n",
    "    y[x>lim] = np.poly1d(coef)(lim)\n",
    "    y[x<-3.3] = np.poly1d(coef)(-3.3)\n",
    "    return denorm(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlin = np.linspace(lims['log_deformation_0'][0],lims['log_deformation_0'][1],100)\n",
    "\n",
    "y_ak_lin = reg_ak(xlin)\n",
    "y_jb_lin = reg_jb(xlin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "xx = Xtrain[:,dsize//2,dsize//2,0].ravel()\n",
    "yy = denorm(ytrain).ravel()\n",
    "\n",
    "ax.hist2d(xx,yy,  50, [lims['log_deformation_0'],lims['damage'] ], norm=mpl.colors.LogNorm(), cmap='jet');\n",
    "ax.set_xlabel('Deformation (log)')\n",
    "ax.set_ylabel('Damage (denormalized)');\n",
    "fig.savefig(os.path.join(figdir, f'hist2.png'))\n",
    "\n",
    "ax.plot(xpoint,denorm(ypoint),'+k')\n",
    "ax.plot(xlin,y_jb_lin,'-k',label=\"jb baseline\")\n",
    "ax.plot(xlin,y_ak_lin,':k',label=\"ak baseline\")\n",
    "\n",
    "ax.legend(loc='lower right')\n",
    "fig.savefig(os.path.join(figdir, f'hist2_baseline{suff}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ak = reg_ak(Xval[:,dsize//2,dsize//2,0])\n",
    "y_jb = reg_jb(Xval[:,dsize//2,dsize//2,0])\n",
    "yval_d = denorm(yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.path.join(model_dir,model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(os.path.join(model_dir,model_name))\n",
    "ypredict = denorm(model.predict(Xval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "xylims = lims['damage']\n",
    "\n",
    "\n",
    "ax.hist2d(yval_d.ravel(),y_ak.ravel(),  50, [xylims, xylims], norm=mpl.colors.LogNorm()),\n",
    "ax.plot(xylims,xylims,'k',linewidth=2)\n",
    "#ax.set_title('Anton (AK)')\n",
    "fig.savefig(os.path.join(figdir, f'scatter_ak{suff}.png'))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "ax.hist2d(yval_d.ravel(),y_jb.ravel(),  50, [xylims, xylims], norm=mpl.colors.LogNorm()),\n",
    "ax.plot(xylims,xylims,'k',linewidth=2)\n",
    "#ax[2].set_title('Julien (JB)');\n",
    "fig.savefig(os.path.join(figdir, f'scatter_jb{suff}.png'))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "ax.hist2d(yval_d.ravel(),ypredict.ravel(),  50, [xylims, xylims], norm=mpl.colors.LogNorm()),\n",
    "ax.plot(xylims,xylims,'k',linewidth=2)\n",
    "#ax[2].set_title('Julien (JB)');\n",
    "fig.savefig(os.path.join(figdir, f'scatter_nn{suff}.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrue = yval_d > .95\n",
    "cak = y_ak>.95\n",
    "cjb = y_jb>.95\n",
    "cnn = ypredict>.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ctrue, cak))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ctrue, cjb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ctrue, cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print correlation\n",
    "mask= None \n",
    "\n",
    "corr_nn = corr(yval_d[mask].ravel(), ypredict[mask].ravel())\n",
    "corr_ak = corr(yval_d[mask].ravel(), y_ak[mask].ravel())\n",
    "corr_jb = corr(yval_d[mask].ravel(), y_jb[mask].ravel())\n",
    "print(f'corr NN: {corr_nn:.2f}\\ncorr ak: {corr_ak:.2f}\\ncorr jb: {corr_jb:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Inputs features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(colnames):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    im = ax.imshow(Xval[10,...,i],vmin=lims[name][0],vmax=lims[name][1])\n",
    "    rect=mpl.patches.Rectangle((11.5, 11.5), 1, 1, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(12,26,'$x_c$',fontsize='x-large',ha='center')\n",
    "    ax.text(-2.5,12,'$y_c$',fontsize='x-large',va='center')\n",
    "    ax.plot([-0.5,12],[12,12],':',color='red')\n",
    "    ax.plot([12,12],[12,24.5],':',color='red')\n",
    "    fig.savefig(os.path.join(figdir, f'patch_{name}{suff}.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del Xtrain, ytrain, X, y\n",
    "except:\n",
    "    pass\n",
    "data_test = np.load(os.path.join(traindir,'test.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_test = denorm(model.predict(Xtest))\n",
    "y_ak_test = reg_ak(Xtest[:,dsize//2,dsize//2,0])\n",
    "y_jb_test = reg_jb(Xtest[:,dsize//2,dsize//2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, y2_pred = unstack_training(Xtest, ypred_test, mask_test, ny=ny, nx=nx, strides=1)\n",
    "X2, y2_ak = unstack_training(Xtest, y_ak_test, mask_test, ny=ny, nx=nx, strides=1)\n",
    "X2, y2_jb = unstack_training(Xtest, y_jb_test, mask_test, ny=ny, nx=nx, strides=1)\n",
    "\n",
    "y2_test = y2_test.squeeze()\n",
    "y2_pred = y2_pred.squeeze()\n",
    "y2_ak = y2_ak.squeeze()\n",
    "y2_jb = y2_jb.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_jb = y2_jb-y2_test\n",
    "delta_ak = y2_ak-y2_test\n",
    "delta_pred = y2_pred-y2_test\n",
    "\n",
    "#Mask values below the threshold\n",
    "delta_jb[y2_test<th_dam] = np.nan\n",
    "delta_ak[y2_test<th_dam] = np.nan\n",
    "delta_pred[y2_test<th_dam] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=3,figsize=(16,4))\n",
    "dam = ax[0].imshow(y2_test,vmin=lims['damage'][0], vmax = lims['damage'][1],cmap='jet')\n",
    "ax[1].imshow(y2_ak,vmin=lims['damage'][0], vmax=lims['damage'][1],cmap='jet')\n",
    "ax[2].imshow(y2_pred,vmin=lims['damage'][0], vmax=lims['damage'][1],cmap='jet')\n",
    "fig.colorbar(dam, ax=ax.ravel().tolist(),orientation='horizontal');\n",
    "clean_ax(ax)\n",
    "ax[0].set_title('Truth');\n",
    "ax[1].set_title('Baseline (AK)');\n",
    "ax[2].set_title('CNN');\n",
    "fig.savefig(os.path.join(figdir, f'test_image{suff}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2,figsize=(10,4))\n",
    "err = ax[0].imshow(delta_ak,vmin=-0.1,vmax=0.1,cmap=plt.get_cmap('bwr'))\n",
    "ax[1].imshow(delta_pred,vmin=-0.1,vmax=0.1,cmap=plt.get_cmap('bwr'))\n",
    "\n",
    "fig.colorbar(err, ax=ax.ravel().tolist(),orientation='horizontal');\n",
    "clean_ax(ax)\n",
    "ax[0].set_title('Baseline (AK) err');\n",
    "ax[1].set_title('CNN err');\n",
    "fig.savefig(os.path.join(figdir, f'test_image_err{suff}.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Explainibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output features od the validation set\n",
    "X_sk = Xval\n",
    "y_sk = denorm(yval)\n",
    "\n",
    "# Define the score\n",
    "def score_nn (X, y):\n",
    "    ypredict = denorm(model.predict(X))\n",
    "    return corr(y.ravel(), ypredict.ravel())\n",
    "\n",
    "# Compute the score of each feature (the computation is done n_iter times corresponding to n_iter different random shuffle)\n",
    "base_score, score_decreases = get_score_importances(score_nn, \n",
    "                                                    X_sk, \n",
    "                                                    y_sk, \n",
    "                                                    n_iter=10, \n",
    "                                                    pre_shuffle=True\n",
    "                                                   )\n",
    "\n",
    "# Compute the mean importance of each input feature\n",
    "score_mean = np.mean(score_decreases, axis=0)\n",
    "score_std = np.std(score_decreases, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the importance\n",
    "y_pos = np.arange(len(colnames)+1)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.barh(y_pos[1:], base_score-score_mean, xerr=score_std, align='center')\n",
    "ax.barh(y_pos[0],base_score)\n",
    "ax.set_yticks(y_pos);\n",
    "ax.set_yticklabels(('base score',)+colnames)\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel('Correlation')\n",
    "ax.set_title('Feature importance');\n",
    "fig.savefig(os.path.join(figdir, f'feature_importance{suff}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_keras_vis.saliency import Saliency\n",
    "saliency = Saliency(model,\n",
    "                    model_modifier=None,\n",
    "                    clone=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of sample used to calculate the saliency map\n",
    "n_sample = 2000\n",
    "\n",
    "# Define the loss for the gradient computation\n",
    "def loss(output):\n",
    "    return tuple(output[i] for i in range(n_sample))\n",
    "\n",
    "# Compute the saliency map for each input feature (keepdims=True)\n",
    "saliency_map = saliency(loss, Xval[:n_sample], keepdims=True)\n",
    "\n",
    "# Compute the average saliency map\n",
    "saliency_absmean = np.abs(saliency_map).mean(axis=0)\n",
    "\n",
    "# To be used to normalize the saliency map with the standard deviation\n",
    "sigma_in = np.sqrt(model.layers[2].variance.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = len(exp_dict['colnames'])\n",
    "vmax = .1 #saliency_absmean.max()\n",
    "fig, ax = plt.subplots(ncols=nc,figsize=(5*nc,5))\n",
    "for i in range(nc):\n",
    "    vmax = saliency_absmean[...,i].max()\n",
    "    im = ax[i].imshow(saliency_absmean[...,i], cmap='jet', vmax = vmax)\n",
    "    ax[i].set_title(exp_dict['colnames'][i])\n",
    "    fig.colorbar(im, ax=ax[i],orientation='horizontal');\n",
    "\n",
    "#fig.colorbar(im, ax=ax.ravel().tolist(),orientation='horizontal');\n",
    "fig.suptitle ('Mean saliency map');\n",
    "fig.savefig(os.path.join(figdir, f'saliency{suff}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
