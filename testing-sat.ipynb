{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport dti_util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "from dti_util import default, stack_training, unstack_training, clean_ax\n",
    "import autokeras as ak #Necessary to import otherwise load_model does not work\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import matplotlib as mpl\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.gridspec as gridspec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change default matplotlib\n",
    "mpl.rcParams['savefig.dpi']=150\n",
    "mpl.rcParams['savefig.bbox']='tight'\n",
    "mpl.rcParams['savefig.pad_inches']=0.1\n",
    "mpl.rcParams['axes.labelsize']=mpl.rcParams['axes.titlesize']\n",
    "plt.rcParams['savefig.facecolor']='white'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the experiment\n",
    "name = 'exp-sr-sat-hr-smallpatch'\n",
    "\n",
    "# Name of the model\n",
    "model_name = \"long\"\n",
    "\n",
    "# Root of all directories used\n",
    "rootdir = '/mnt/sfe-ns9602k/Julien/data'\n",
    "\n",
    "# save figure\n",
    "savefig = True\n",
    "figdir = 'figs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- EXPERIMENT SETTING ----\n",
      "smooth_output  :  4\n",
      "strides_test  :  2\n",
      "smooth_drift  :  30\n",
      "smooth_sic  :  6\n",
      "smooth_sit  :  30\n",
      "scale  :  False\n",
      "epsi  :  None\n",
      "targetname  :  h\n",
      "targetfullname  :  SIT\n",
      "colnames  :  ('e2_0', 'c', 'h', 'e1_0')\n",
      "datadir  :  /mnt/sfe-ns9602k/Julien/data/anton/shom5km_defor_4cnn\n",
      "dsize  :  7\n",
      "end_train  :  400\n",
      "itest  :  1\n",
      "name  :  exp-sr-sat-hr-smallpatch\n",
      "othernames  :  ('c',)\n",
      "rootdir  :  /mnt/sfe-ns9602k/Julien/data\n",
      "start_train  :  10\n",
      "strides  :  20\n",
      "subd  :  2\n",
      "th_dam  :  0.0\n",
      "th_sic  :  0.2\n",
      "th_sit  :  0.0\n",
      "traindir  :  /mnt/sfe-ns9602k/Julien/data/exp-sr-sat-hr-smallpatch/train\n",
      "\n",
      "---- MODEL SETTING ----\n",
      "epochs  :  300\n",
      "fname_score_saliency  :  saliency_score\n",
      "fname_score_shuffle  :  shuffle_score\n",
      "log_dir  :  /mnt/sfe-ns9602k/.tools/deep-learn-1603280065-tensorboard/autokeras/exp-sr-sat-hr-smallpatch-long\n",
      "max_trials  :  50\n",
      "ntrain  :  None\n",
      "patience  :  15\n",
      "split_seed  :  1\n",
      "target_th  :  0.95\n",
      "test_size  :  0.15\n",
      "type  :  reg\n",
      "\n",
      "---- SAT SETTING ----\n",
      "datadir  :  /mnt/sfe-ns9602k/Julien/data/anton/sat_data_4cnn\n",
      "factors  :  {'divergence': 1.1574074074074073e-05, 'divergence_sar': 1.1574074074074073e-05, 'shear': 1.1574074074074073e-05, 'shear_sar': 1.1574074074074073e-05, 'sic': 0.01}\n",
      "outname  :  sit_nn_{date}.npy\n",
      "path  :  /mnt/sfe-ns9602k/Julien/data/exp-sr-sat-hr-smallpatch/sat\n",
      "sar  :  False\n",
      "strides_test  :  1\n",
      "subd  :  1\n",
      "timname  :  sat_image_{date}.npy\n",
      "tname  :  sat_input_{date}.npz\n"
     ]
    }
   ],
   "source": [
    "# Directory of the experiment outputs\n",
    "expdir = os.path.join(rootdir, name)\n",
    "\n",
    "# Directory of the model\n",
    "model_dir = os.path.join(expdir, model_name)\n",
    "\n",
    "# Load experiment parameters\n",
    "with open(os.path.join(expdir,'data_params.yml' )) as file:\n",
    "    exp_dict = yaml.load(file, Loader=yaml.FullLoader)\n",
    "exp_dict = {**default, **exp_dict}\n",
    "    \n",
    "# Print experiments parameters\n",
    "print('---- EXPERIMENT SETTING ----')\n",
    "for key, value in exp_dict.items():\n",
    "    print(key, ' : ', value)\n",
    "\n",
    "print('\\n---- MODEL SETTING ----')\n",
    "with open(os.path.join(model_dir,'model_params.yml' )) as file:\n",
    "    dmod = yaml.load(file, Loader=yaml.FullLoader)   \n",
    "for key, value in dmod.items():\n",
    "    print(key, ' : ', value)\n",
    "    \n",
    "print('\\n---- SAT SETTING ----')\n",
    "with open(os.path.join(expdir,'sat_params.yml' )) as file:\n",
    "    dsat = yaml.load(file, Loader=yaml.FullLoader)   \n",
    "for key, value in dsat.items():\n",
    "    print(key, ' : ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_path = dsat['path']\n",
    "fig_path = os.path.join(sat_path,figdir)\n",
    "\n",
    "if not os.path.isdir(fig_path):\n",
    "    os.makedirs(fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c': 'sic', 'h': 'sit', 'e1_0': 'divergence', 'e2_0': 'shear'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sit': (0.0, 3),\n",
       " 'sic': (0, 1),\n",
       " 'divergence': (-5e-07, 5e-07),\n",
       " 'shear': (0.0, 1e-06)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1lim = (-5e-7,5e-7)\n",
    "e2lim = (0.,1e-6)\n",
    "lims = {\n",
    "    'log_deformation_0': (-4, 1),\n",
    "    'log_deformation_1': (-4, 1),\n",
    "    'h':(exp_dict['th_sit'],3),\n",
    "    'c':(0,1),\n",
    "    'd':(exp_dict['th_dam'], 1.),\n",
    "    'e1_0': e1lim,\n",
    "    'e1_1': e1lim,\n",
    "    'e2_0': e2lim,\n",
    "    'e2_1': e2lim,\n",
    "}\n",
    "\n",
    "# Corresponsdance\n",
    "suff = '_sar' if dsat['sar'] else ''\n",
    "mod2sat = dict(\n",
    "    c='sic',\n",
    "    h='sit',\n",
    "    e1_0='divergence'+suff,\n",
    "    e2_0='shear'+suff)\n",
    "print(mod2sat)\n",
    "\n",
    "lims_sat = {mod2sat[k]:v for k,v in lims.items() if k in mod2sat}\n",
    "lims_sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No scaling\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model_dir =  os.path.join(expdir, model_name)\n",
    "model = load_model(os.path.join(model_dir,model_name), compile=False)\n",
    "scale = exp_dict['scale']\n",
    "\n",
    "if scale is True:\n",
    "    epsi = exp_dict['epsi']\n",
    "    th_dam = exp_dict['th_dam']\n",
    "\n",
    "    print('Scaling the output')\n",
    "    from dti_util import code_dam, decode_dam\n",
    "    # Normalization function\n",
    "    norm = lambda x : code_dam(x,epsi=epsi, vmin=th_dam)\n",
    "\n",
    "    # Denormalization function\n",
    "    denorm = lambda x : decode_dam(x,epsi=epsi, vmin=th_dam)\n",
    "else:\n",
    "    print('No scaling')\n",
    "\n",
    "    norm = lambda x : x\n",
    "    denorm = lambda x : x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 7, 7, 4)]         0         \n",
      "_________________________________________________________________\n",
      "cast_to_float32 (CastToFloat (None, 7, 7, 4)           0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 7, 7, 4)           9         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 5, 5, 32)          1184      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 5, 5, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 2, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 256)         73984     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "regression_head_2 (Dense)    (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 93,930\n",
      "Trainable params: 93,921\n",
      "Non-trainable params: 9\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 files found\n"
     ]
    }
   ],
   "source": [
    "fname = dsat['tname'].format(date='*')\n",
    "lfiles=list(map(os.path.basename,sorted(glob.glob(os.path.join(sat_path,fname)))))\n",
    "n = len(lfiles)\n",
    "print(f'{n} files found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sat_input_20210101.npz',\n",
       " 'sat_input_20210201.npz',\n",
       " 'sat_input_20210301.npz',\n",
       " 'sat_input_20210401.npz',\n",
       " 'sat_input_20210501.npz',\n",
       " 'sat_input_20210601.npz',\n",
       " 'sat_input_20210701.npz',\n",
       " 'sat_input_20210801.npz',\n",
       " 'sat_input_20210901.npz',\n",
       " 'sat_input_20211001.npz',\n",
       " 'sat_input_20211101.npz',\n",
       " 'sat_input_20211201.npz',\n",
       " 'sat_input_20211301.npz',\n",
       " 'sat_input_20211401.npz',\n",
       " 'sat_input_20211501.npz',\n",
       " 'sat_input_20211601.npz',\n",
       " 'sat_input_20211701.npz',\n",
       " 'sat_input_20211801.npz',\n",
       " 'sat_input_20211901.npz',\n",
       " 'sat_input_20212001.npz',\n",
       " 'sat_input_20212101.npz',\n",
       " 'sat_input_20212201.npz',\n",
       " 'sat_input_20212301.npz',\n",
       " 'sat_input_20212401.npz',\n",
       " 'sat_input_20212501.npz',\n",
       " 'sat_input_20212601.npz',\n",
       " 'sat_input_20212701.npz',\n",
       " 'sat_input_20212801.npz',\n",
       " 'sat_input_20212901.npz',\n",
       " 'sat_input_20213001.npz',\n",
       " 'sat_input_20213101.npz']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indx = slice(n)\n",
    "lfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the date index\n",
    "idate = dsat['tname'].index('{')\n",
    "dateind = slice(idate,idate+8) # 8 == YYYYDDMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e21bcbf93943a5b5832a5173fd858d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sat_input_20210101.npz\n",
      "2602.53125\n",
      "sat_input_20210201.npz\n",
      "2744.40234375\n",
      "sat_input_20210301.npz\n",
      "2751.84375\n",
      "sat_input_20210401.npz\n",
      "2861.48828125\n",
      "sat_input_20210501.npz\n",
      "2871.359375\n",
      "sat_input_20210601.npz\n",
      "2982.6015625\n",
      "sat_input_20210701.npz\n",
      "3092.875\n",
      "sat_input_20210801.npz\n",
      "3094.578125\n",
      "sat_input_20210901.npz\n",
      "3202.46875\n",
      "sat_input_20211001.npz\n",
      "3202.89453125\n",
      "sat_input_20211101.npz\n",
      "3309.8125\n",
      "sat_input_20211201.npz\n",
      "3417.3984375\n",
      "sat_input_20211301.npz\n",
      "3419.265625\n",
      "sat_input_20211401.npz\n",
      "3528.6328125\n",
      "sat_input_20211501.npz\n",
      "3528.60546875\n",
      "sat_input_20211601.npz\n",
      "3645.37109375\n",
      "sat_input_20211701.npz\n",
      "3754.4609375\n",
      "sat_input_20211801.npz\n",
      "3755.37890625\n",
      "sat_input_20211901.npz\n",
      "3866.41015625\n",
      "sat_input_20212001.npz\n",
      "3978.6640625\n",
      "sat_input_20212101.npz\n",
      "3979.56640625\n",
      "sat_input_20212201.npz\n",
      "2690.5859375\n",
      "sat_input_20212301.npz\n",
      "2802.28125\n",
      "sat_input_20212401.npz\n",
      "2913.9296875\n",
      "sat_input_20212501.npz\n",
      "2914.25\n",
      "sat_input_20212601.npz\n",
      "3026.5234375\n",
      "sat_input_20212701.npz\n",
      "3139.4375\n",
      "sat_input_20212801.npz\n",
      "3139.859375\n",
      "sat_input_20212901.npz\n",
      "3252.68359375\n",
      "sat_input_20213001.npz\n",
      "3366.2109375\n",
      "sat_input_20213101.npz\n",
      "3366.40234375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dsize = exp_dict['dsize']\n",
    "strides_test = dsat['strides_test']\n",
    "subd = dsat['subd']\n",
    "ypredict = None\n",
    "import psutil\n",
    "for file in tqdm(lfiles[indx]):\n",
    "    date = file[dateind]\n",
    "    fname = dsat['tname'].format(date=date)\n",
    "    print(fname)\n",
    "    with np.load(os.path.join(dsat['path'],fname)) as data:\n",
    "        Xtest = data['Xtest']\n",
    "        mask_test = data['mask_test']\n",
    "        ny = data['ny']\n",
    "        nx = data['nx']\n",
    "    if Xtest.size>0:\n",
    "        ypredict_tmp = denorm(model.predict(Xtest))\n",
    "        X2, y2_pred = unstack_training(Xtest, ypredict_tmp, mask_test, ny=ny, nx=nx, subd=subd, strides=strides_test, squeezey=False)\n",
    "        y2_pred = y2_pred.squeeze()\n",
    "        fname = dsat['outname'].format(date=date)\n",
    "        np.save(os.path.join(dsat['path'],fname),y2_pred)\n",
    "        del X2, y2_pred\n",
    "    del  Xtest, mask_test\n",
    "    print(psutil.Process().memory_info().rss / (1024 * 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0e1dc13e5b42b0b3a7db3dc87d29fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "colnames = [mod2sat[c] for c in exp_dict['colnames']]\n",
    "nc = len(colnames)\n",
    "\n",
    "for file in tqdm(lfiles[indx]):\n",
    "    date = file[dateind]\n",
    "    fname = dsat['timname'].format(date=date)\n",
    "    Xim = np.load(os.path.join(dsat['path'],fname))\n",
    "    fname = dsat['outname'].format(date=date)\n",
    "    if os.path.isfile(os.path.join(dsat['path'],fname)):\n",
    "        y2_pred = np.load(os.path.join(dsat['path'],fname))\n",
    "    else:\n",
    "        continue\n",
    "    fig = plt.figure(figsize=(5*nc,17))\n",
    "\n",
    "    gs = gridspec.GridSpec(nrows=2, ncols=4, height_ratios=[2, 1])\n",
    "\n",
    "    for ic, c in enumerate(colnames):\n",
    "        ax = fig.add_subplot(gs[1,ic])\n",
    "        vmin, vmax = lims_sat[c]\n",
    "        co=ax.imshow(Xim[0,...,ic], cmap='jet', vmin=vmin, vmax=vmax)\n",
    "        fig.colorbar(co, ax=ax, orientation='horizontal')\n",
    "        clean_ax([ax])\n",
    "        ax.set_xlim((200,700))\n",
    "        ax.set_ylim((200,700))\n",
    "        ax.set_title(c)\n",
    "    ax = fig.add_subplot(gs[0,:2])\n",
    "    vmin, vmax = lims_sat['sit']\n",
    "    co=ax.imshow(y2_pred, cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    ax.set_xlim((200,700))\n",
    "    ax.set_ylim((200,700))\n",
    "    ax.set_title('NN SIT')\n",
    "    clean_ax([ax])\n",
    "    fig.colorbar(co, ax=ax, orientation='horizontal')\n",
    "\n",
    "    ax = fig.add_subplot(gs[0,2:4])\n",
    "    vmin, vmax = -.8,.8\n",
    "    ih = colnames.index('sit')\n",
    "    co=ax.imshow(y2_pred-Xim[0,...,ih], cmap='bwr', vmin=vmin, vmax=vmax)\n",
    "    ax.set_xlim((200,700))\n",
    "    ax.set_ylim((200,700))\n",
    "    ax.set_title('HR minus LR')\n",
    "    clean_ax([ax])\n",
    "    \n",
    "    \n",
    "    fig.colorbar(co, ax=ax, orientation='horizontal',extend='both')\n",
    "    fig.suptitle(date)\n",
    "    if savefig:\n",
    "        figname = f'SIT-NN-{date}.png'\n",
    "        fig.savefig(os.path.join(fig_path,figname))\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
